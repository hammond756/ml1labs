{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Save this file as studentid1_studentid2_lab#.ipynb**\n",
    "(Your student-id is the number shown on your student card.)\n",
    "\n",
    "E.g. if you work with 3 people, the notebook should be named:\n",
    "12301230_3434343_1238938934_lab1.ipynb.\n",
    "\n",
    "**This will be parsed by a regexp, so please double check your filename.**\n",
    "\n",
    "Before you turn this problem in, please make sure everything runs correctly. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "**Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your names and email adresses below.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAME = \"Aron Hammond\"\n",
    "NAME2 = \"Tijmen van Dijk\"\n",
    "NAME3 = \"David Stap\"\n",
    "EMAIL = \"hammond756@live.nl\"\n",
    "EMAIL2 = \"vandijktijmen@gmail.com\"\n",
    "EMAIL3 = \"dd.stap@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a95dc04cc0041b2e947db42c31ab650b",
     "grade": false,
     "grade_id": "cell-447a8ab4c82429ab",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Lab 3: Gaussian Processes and Support Vector Machines\n",
    "\n",
    "### Machine Learning 1, September 2017\n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should write your code and answers in this IPython Notebook: http://ipython.org/notebook.html. If you have problems, please contact your teaching assistant.\n",
    "* Please write your answers right below the questions.\n",
    "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline.\n",
    "* Refer to last week's lab notes, i.e. http://docs.scipy.org/doc/, if you are unsure about what function to use. There are different correct ways to implement each problem!\n",
    "* use the provided test boxes to check if your answers are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9c278ee9abc89a5ef5d829c1049141d2",
     "grade": false,
     "grade_id": "cell-a31fbe1e5a0de9bb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.rcParams[\"figure.figsize\"] = [20,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7305e08b2c04f7ba3de1071d310b4a79",
     "grade": false,
     "grade_id": "cell-9f5845b06688e6e3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 1: Gaussian Processes\n",
    "\n",
    "For part 1 we will be refer to Bishop sections 6.4.2 and 6.4.3. You may also want to refer to Rasmussen's Gaussian Process text which is available online at http://www.gaussianprocess.org/gpml/chapters/ and especially to the project found at https://www.automaticstatistician.com/index/ by Ghahramani for some intuition in GP.  To understand Gaussian processes, it is highly recommended understand how marginal, partitioned Gaussian distributions can be converted into conditional Gaussian distributions.  This is covered in Bishop 2.3 and summarized in Eqns 2.94-2.98.\n",
    "$\\newcommand{\\bt}{\\mathbf{t}}$\n",
    "$\\newcommand{\\bx}{\\mathbf{x}}$\n",
    "$\\newcommand{\\by}{\\mathbf{y}}$\n",
    "$\\newcommand{\\bw}{\\mathbf{w}}$\n",
    "$\\newcommand{\\ba}{\\mathbf{a}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2c77bcc3c1b41adb15916666630bde13",
     "grade": false,
     "grade_id": "cell-c5f5f5b7b143efaa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Periodic Data\n",
    "\n",
    "We will use the same data generating function that we used previously for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f934af0cdc6013c2c4ce2898143e4e29",
     "grade": false,
     "grade_id": "cell-4f7ad28294ae4fe4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def true_mean_function(x):\n",
    "    return np.cos(2*pi*(x+1))\n",
    "\n",
    "def add_noise(y, sigma):\n",
    "    return y + sigma*np.random.randn(len(y))\n",
    "\n",
    "def generate_t(x, sigma):\n",
    "    return add_noise(true_mean_function(x), sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d61908ff838f72d6bf5b7527be6f44fb",
     "grade": false,
     "grade_id": "cell-31ff6786c5cd8a8d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI0AAAJCCAYAAABNpjdvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGgEAAAAw8n9zJwn9bHV0fQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6e73dbdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma = 0.2\n",
    "beta  = 1.0 / pow(sigma, 2)\n",
    "N_test = 100\n",
    "\n",
    "x_test = np.linspace(-1, 1, N_test) \n",
    "mu_test = np.zeros(N_test)\n",
    "y_test = true_mean_function(x_test)\n",
    "t_test = add_noise(y_test, sigma)\n",
    "\n",
    "plt.plot( x_test, y_test, 'b-', lw=2)\n",
    "plt.plot( x_test, t_test, 'go')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "36d45d85a96792d4b255ee32d35e6eea",
     "grade": false,
     "grade_id": "cell-97e93e61042ddefb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1. Sampling from the Gaussian process prior (30 points)\n",
    "We will implement Gaussian process regression using the kernel function in Bishop Eqn. 6.63.  \n",
    "\n",
    "#### 1.1 k_n_m( xn, xm, thetas ) (5 points)\n",
    "To start, implement function `k_n_m(xn, xm, thetas)` that takes scalars $x_n$ and $x_m$, and a vector of $4$ thetas, and computes the kernel function Bishop Eqn. 6.63 (10 points).  NB: usually the kernel function will take $D$ by $1$ vectors, but since we are using a univariate problem, this makes things easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e9e7f20ba77a7ec760497ae005ddd509",
     "grade": false,
     "grade_id": "cell-10f11f2e5e6b38e6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def k_n_m(xn, xm, thetas):\n",
    "    return thetas[0] * exp(-1*(thetas[1]/2)*(pow(xn-xm,2))) + thetas[2] + thetas[3]*(xn*xm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a698a7c4d51ed717398be46a064cc736",
     "grade": true,
     "grade_id": "cell-8b621bd13ef5af5e",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.000003726653169"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn = 5\n",
    "xm = 10\n",
    "thetas = [1, 1, 1, 1]\n",
    "\n",
    "k_n_m(xn, xm, thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "36dec709c43411cce4c9ee71c90c3c3b",
     "grade": false,
     "grade_id": "cell-ad0a764e2a661bc8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.2 computeK( X1, X2, thetas ) (10 points)\n",
    "Eqn 6.60 is the marginal distribution of mean output of $N$ data vectors: $p(\\mathbf{y}) = \\mathcal{N}(0, \\mathbf{K})$.  Notice that the expected mean function is $0$ at all locations, and that the covariance is a $N$ by $N$ kernel matrix $\\mathbf{K}$.  Write a function `computeK(x1, x2, thetas)`\n",
    "that computes the kernel matrix. Use k_n_m as part of an inner loop (of course, there are more efficient ways of computing the kernel function making better use of vectorization, but that is not necessary) (5 points).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b211dee5ab3a8c03c0e231f7018a5f6c",
     "grade": false,
     "grade_id": "cell-a71c407c04df7096",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Function that corrects the floating point errors encured while \n",
    "# calculating a covariance matrix. \n",
    "# source: https://stackoverflow.com/questions/41515522/numpy-positive-semi-definite-warning\n",
    "def make_psd(cov):\n",
    "    min_eig = np.min(np.real(np.linalg.eigvals(cov)))\n",
    "    if min_eig < 0:\n",
    "        print(\"Applied make_psd\")\n",
    "        cov -= 10*min_eig * np.eye(cov.shape[0])\n",
    "    return cov\n",
    "\n",
    "def computeK(x1, x2, thetas):\n",
    "    K = empty([len(x1),len(x2)])\n",
    "    \n",
    "    for n in range(len(x1)):\n",
    "        for m in range(len(x2)):\n",
    "            K[n][m] = k_n_m(x1[n], x2[m], thetas)\n",
    "    \n",
    "    return make_psd(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "029e83953d65a4b5acdb0893a500fca7",
     "grade": true,
     "grade_id": "cell-b306210055d7a91c",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9fc8e6b67298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mthetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"the shape of K is incorrect\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-d94572703fac>\u001b[0m in \u001b[0;36mcomputeK\u001b[1;34m(x1, x2, thetas)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_n_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmake_psd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-d94572703fac>\u001b[0m in \u001b[0;36mmake_psd\u001b[1;34m(cov)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# source: https://stackoverflow.com/questions/41515522/numpy-positive-semi-definite-warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_psd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmin_eig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meigvals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmin_eig\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Applied make_psd\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml1labs\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36meigvals\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    886\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m     \u001b[0m_assertNdSquareness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[0m_assertFinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml1labs\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_assertNdSquareness\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Last 2 dimensions of the array must be square'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_assertFinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "source": [
    "### Test your function\n",
    "x1 = [0, 1, 2]\n",
    "x2 = [1, 2, 3, 4]\n",
    "thetas = [1, 2, 3, 4]\n",
    "K = computeK(x1, x2, thetas)\n",
    "\n",
    "assert K.shape == (len(x1), len(x2)), \"the shape of K is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f57364d4f797028880d45068be8220a6",
     "grade": false,
     "grade_id": "cell-b57ae041bde18cd1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.3 Plot function samples (15 points)\n",
    "Now sample mean functions at the x_test locations for the theta values in Bishop Figure 6.5, make a figure with a 2 by 3 subplot and make sure the title reflects the theta values (make sure everything is legible).  In other words, sample $\\by_i \\sim \\mathcal{N}(0, \\mathbf{K}_{\\theta})$.  Make use of numpy.random.multivariate_normal().  On your plots include the expected value of $\\by$ with a dashed line and fill_between 2 standard deviations of the uncertainty due to $\\mathbf{K}$ (the diagonal of $\\mathbf{K}$ is the variance of the model uncertainty) (15 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2d5e7a8803ed3dae7274a8d464ee8803",
     "grade": true,
     "grade_id": "cell-1424adaf2517b28b",
     "locked": false,
     "points": 15,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define thetas in the prefered shape of the pots: N x M. \n",
    "# Corresponding plots will show up in the same location in the figure.\n",
    "theta_values = np.array([[[1,4,0,0], [9,4,0,0], [1, 64, 0, 0]], \n",
    "                         [[1, 0.25, 0, 0], [1,4,10,0], [1,4,0,5]]])\n",
    "\n",
    "# create subplots for each set of thetas\n",
    "fig, axes = plt.subplots(theta_values.shape[0], theta_values.shape[1])\n",
    "for n in range(theta_values.shape[0]):\n",
    "    for m in range(theta_values.shape[1]):\n",
    "        \n",
    "        # Define elements of this iteration\n",
    "        theta_k = theta_values[n,m]\n",
    "        subplot = axes[n][m]\n",
    "        \n",
    "        # Calculate kernel and correct the floating point errors\n",
    "        K = computeK(x_test, x_test, theta_k)\n",
    "        K = make_psd(K)\n",
    "\n",
    "        # Set title for subplot m, n\n",
    "        subplot.set_title(\"Theta's: \" + str(theta_k))\n",
    "        \n",
    "        # Sample from N(0, K)\n",
    "        Y = np.random.multivariate_normal(np.zeros(K.shape[0]), K, size=5)\n",
    "        y_mean = Y.mean(0)\n",
    "        std = Y.std(0)\n",
    "        \n",
    "        # Plot samples\n",
    "        for y in Y:\n",
    "            subplot.plot(x_test, y)\n",
    "        \n",
    "        # Plot mean of samples with +std and -std\n",
    "        subplot.plot(x_test, y_mean, '--', color=\"black\")\n",
    "        subplot.fill_between(x_test, y_mean+std, y_mean-std, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a1426876a05c35eab0f5289a1f503e1",
     "grade": false,
     "grade_id": "cell-2a25f52361101417",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2. Predictive distribution (35 points)\n",
    "So far we have sampled mean functions from the prior.  We can draw actual data $\\bt$ two ways.  The first way is generatively, by first sampling $\\by | \\mathbf{K}$, then sampling $\\bt | \\by, \\beta$ (Eqns 6.60 followed by 6.59).  The second way is to integrate over $\\by$ (the mean draw) and directly sample $\\bt | \\mathbf{K}, \\beta$ using Eqn 6.61.    This is the generative process for $\\bt$.  Note that we have not specified a distribution over inputs $\\bx$;  this is because Gaussian processes are conditional models.  Because of this we are free to generate locations $\\bx$ when playing around with the GP; obviously a dataset will give us input-output pairs.\n",
    "\n",
    "Once we have data, we are interested in the predictive distribution (note: the prior is the predictive distribution when there is no data).  Consider the joint distribution for $N+1$ targets, given by Eqn 6.64.  Its covariance matrix is composed of block components $C_N$, $\\mathbf{k}$, and $c$.  The covariance matrix $C_N$ for $\\bt_N$ is $C_N = \\mathbf{K}_N + \\beta^{-1}\\mathbf{I}_N$.  We have just made explicit the size $N$ of the matrix; $N$ is the number of training points.  The kernel vector $\\mathbf{k}$ is a $N$ by $1$ vector of kernel function evaluations between the training input data and the test input vector.  The scalar $c$ is a kernel evaluation at the test input.\n",
    "\n",
    "#### 2.1 gp_predictive_distribution(...) (10 points)\n",
    "Write a function `gp_predictive_distribution(x_train, t_train, x_test, theta, beta, C=None)` that computes  Eqns 6.66 and 6.67, except allow for an arbitrary number of test points (not just one) and now the kernel matrix is for training data.  By having C as an optional parameter, we can avoid computing it more than once (for this problem it is unimportant, but for real problems this is an issue).  The function should compute $\\mathbf{C}$, $\\mathbf{k}$, and return the mean, variance and $\\mathbf{C}$.  Do not forget: the computeK function computes $\\mathbf{K}$, not $\\mathbf{C}$! (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "96b3c5cc338703cab5f9d4a6755e6cb4",
     "grade": false,
     "grade_id": "cell-eae0316765be4db6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gp_predictive_distribution(x_train, t_train, x_test, theta, beta, C=None):\n",
    "    \n",
    "    N_train = x_train.shape[0]\n",
    "    N_test = x_test.shape[0]\n",
    "    \n",
    "    # Only compute C if not provided\n",
    "    if not np.any(C):\n",
    "        C = computeK(x_train, x_train, theta) + (1/beta)*np.identity(N_train)\n",
    "    \n",
    "    # Calculate k(i,j) for the training data with all new observations\n",
    "    k_N_test = np.empty([N_train, N_test])    \n",
    "    for i, train in enumerate(x_train):\n",
    "        for j, test in enumerate(x_test):\n",
    "            k_N_test[i,j] = k_n_m(train, test, theta)\n",
    "    \n",
    "    c_N_test = computeK(x_test, x_test, theta) + (1/beta)*np.identity(N_test)\n",
    "\n",
    "    # Calcualte eq6.66 and eq6.67\n",
    "    mean_test = k_N_test.T.dot(np.linalg.inv(C)).dot(t_train)\n",
    "    var_test = c_N_test - k_N_test.T.dot(np.linalg.inv(C)).dot(k_N_test)\n",
    "    \n",
    "    return mean_test, var_test, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b226e159c786f3861aed6e620dbf747f",
     "grade": true,
     "grade_id": "cell-9cc4442de9b765c1",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "N = 2\n",
    "train_x = np.linspace(-1, 1, N)\n",
    "train_t = 2*train_x\n",
    "test_N = 3\n",
    "test_x = np.linspace(-1, 1, test_N) \n",
    "theta = [1, 2, 3, 4]\n",
    "beta = 25\n",
    "test_mean, test_var, C = gp_predictive_distribution(train_x, train_t, test_x, theta, beta, C=None)\n",
    "\n",
    "assert test_mean.shape == (test_N,), \"the shape of mean is incorrect\"\n",
    "assert test_var.shape == (test_N, test_N), \"the shape of var is incorrect\"\n",
    "assert C.shape == (N, N), \"the shape of C is incorrect\"\n",
    "\n",
    "C_in = np.array([[0.804, -0.098168436], [-0.098168436, 0.804]])\n",
    "_, _, C_out = gp_predictive_distribution(train_x, train_t, test_x, theta, beta, C=C_in)\n",
    "\n",
    "assert np.allclose(C_in, C_out), \"C is not reused!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "23db3fc8cc428c985f751486fd78b8be",
     "grade": false,
     "grade_id": "cell-32a51baa7ae3ee88",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2.2 gp_log_likelihood(...) (10 points)\n",
    "To learn the hyperparameters, we would need to compute the log-likelihood of the of the training data.  Implicitly, this is conditioned on the value setting for $\\mathbf{\\theta}$.  Write a function `gp_log_likelihood(x_train, t_train, theta, C=None, invC=None, beta=None)`, where C and invC can be stored and reused. It should return the log-likelihood, `C` and `invC`  (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d5f359f9b03ed6c84b0e6a322d203152",
     "grade": false,
     "grade_id": "cell-b402394536823567",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gp_log_likelihood(x_train, t_train, theta, beta, C=None, invC=None):\n",
    "    \n",
    "    N = x_train.shape[0]\n",
    "    \n",
    "    # Reuse C and invC\n",
    "    if not np.any(C):\n",
    "        C = make_psd(computeK(x_train, x_train, theta) + (1/beta) * np.identity(N))\n",
    "    if not np.any(invC):\n",
    "        invC = np.linalg.inv(C)\n",
    "    \n",
    "    # Eq 6.69\n",
    "    lp = -(1/2) * np.log(np.linalg.det(C)) - (1/2)*t_train.T.dot(invC).dot(t_train) - (N/2) * np.log(2*np.pi)\n",
    "    \n",
    "    return lp, C, invC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_C = None\n",
    "print(np.any(test_C) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a93fbe7914a15c839a99e1d8e8614a34",
     "grade": true,
     "grade_id": "cell-c21cca7e11e01d2f",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "N = 2\n",
    "train_x = np.linspace(-1, 1, N)\n",
    "train_t = 2 * train_x\n",
    "theta = [1, 2, 3, 4]\n",
    "beta = 25\n",
    "lp, C, invC = gp_log_likelihood(train_x, train_t, theta, beta, C=None, invC=None)\n",
    "    \n",
    "assert lp < 0, \"the log-likelihood should smaller than 0\"\n",
    "assert C.shape == (N, N), \"the shape of var is incorrect\"\n",
    "assert invC.shape == (N, N), \"the shape of C is incorrect\"\n",
    "\n",
    "C_in = np.array([[0.804, -0.098168436], [-0.098168436, 0.804]])\n",
    "_, C_out, _ = gp_log_likelihood(train_x, train_t, theta, beta, C=C_in, invC=None)\n",
    "\n",
    "assert np.allclose(C_in, C_out), \"C is not reused!\"\n",
    "\n",
    "invC_in = np.array([[1.26260453, 0.15416407], [0.15416407, 1.26260453]])\n",
    "_, _, invC_out = gp_log_likelihood(train_x, train_t, theta, beta, C=None, invC=invC_in)\n",
    "\n",
    "assert np.allclose(invC_in, invC_out), \"invC is not reused!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a160e0d7511d31668ecef9642c17a86d",
     "grade": false,
     "grade_id": "cell-b8772e6321eac07f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2.3 Plotting (10 points)\n",
    "Repeat the 6 plots above, but this time conditioned on the training points.  Use the periodic data generator to create 2 training points where x is sampled uniformly between $-1$ and $1$.  For these plots, feel free to use the provided function \"gp_plot\".  Make sure you put the parameters in the title and this time also the log-likelihood. Try to understand the two types of uncertainty!  If you do not use `gp_plot(...)`, please add a fill between for the model and target noise. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "95b8d2104f9cc899673d86f8792bc573",
     "grade": false,
     "grade_id": "cell-7bd5ca1b452daca8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def gp_plot( x_test, y_test, mean_test, var_test, x_train, t_train, theta, beta ):\n",
    "    # x_test: \n",
    "    # y_test:    the true function at x_test\n",
    "    # mean_test: predictive mean at x_test\n",
    "    # var_test:  predictive covariance at x_test \n",
    "    # t_train:   the training values\n",
    "    # theta:     the kernel parameters\n",
    "    # beta:      the precision (known)\n",
    "    \n",
    "    # the reason for the manipulation is to allow plots separating model and data stddevs.\n",
    "    std_total = np.sqrt(np.diag(var_test))       # includes all uncertainty, model and target noise \n",
    "    std_model = np.sqrt(std_total**2 - 1.0/beta) # remove data noise to get model uncertainty in stddev\n",
    "    std_combo = std_model + np.sqrt(1.0/beta)    # add stddev (note: not the same as full)\n",
    "    \n",
    "    plt.plot(x_test, y_test, 'b', lw=3)\n",
    "    plt.plot(x_test, mean_test, 'k--', lw=2)\n",
    "    plt.fill_between(x_test, mean_test+2*std_combo,mean_test-2*std_combo, color='k', alpha=0.25)\n",
    "    plt.fill_between(x_test, mean_test+2*std_model,mean_test-2*std_model, color='r', alpha=0.25)\n",
    "    plt.plot(x_train, t_train, 'ro', ms=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ae73d0e79c27fa0b71596e446f5acb52",
     "grade": true,
     "grade_id": "cell-1a3dbf1bd2a106f1",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Size of test and training data\n",
    "N_test = 100\n",
    "N_train = 2\n",
    "\n",
    "# Generate training data\n",
    "np.random.seed(1234)\n",
    "x_train = np.random.uniform(size=N_train)\n",
    "t_train = generate_t(x_train, sigma)\n",
    "\n",
    "# New xs to predict on\n",
    "x_test = np.linspace(-1, 1, N_test)\n",
    "y_test = true_mean_function(x_test)\n",
    "\n",
    "fig, axes = plt.subplots(theta_values.shape[0], theta_values.shape[1])\n",
    "for n in range(theta_values.shape[0]):\n",
    "    for m in range(theta_values.shape[1]):\n",
    "        # Reset C\n",
    "        C = None\n",
    "        invC = None\n",
    "        \n",
    "        # Convenient names for indexed variables\n",
    "        thetas = theta_values[n, m]\n",
    "        subplot = axes[n][m]\n",
    "        \n",
    "        # Select current subplot\n",
    "        plt.axes(subplot)\n",
    "            \n",
    "        mean_test, var_test, C = gp_predictive_distribution(x_train, t_train, x_test, thetas, beta, C)\n",
    "        log_prob, C, invC = gp_log_likelihood(x_train, t_train, thetas, beta, C, invC)\n",
    "        \n",
    "        # Set plot properties\n",
    "        subplot.set_xlim(0, 1)\n",
    "        subplot.set_title(\"Thetas: \" + str(thetas) +\"\\n\" + \"Log(likelihood): \" + str(log_prob))\n",
    "        \n",
    "        # Plot data\n",
    "        gp_plot(x_test, y_test, mean_test, var_test, x_train, t_train, thetas, beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "04e5a0ea661756676c10d6b8d7a11524",
     "grade": false,
     "grade_id": "cell-5709bf749ae02f84",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2.4 More plotting (5 points)\n",
    "Repeat the 6 plots above, but this time conditioned a new set of 10 training points. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "43da7f276e6ae7460306d00355c4b05d",
     "grade": true,
     "grade_id": "cell-b200d0aa0fb56cb7",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "N_test = 1\n",
    "N_train = 10\n",
    "\n",
    "C = None\n",
    "invC = None\n",
    "\n",
    "np.random.seed(1234)\n",
    "x_train = np.random.uniform(size=N_train)\n",
    "t_train = generate_t(x_train, sigma)\n",
    "\n",
    "x_test = np.linspace(-1, 1, N_test)\n",
    "y_test = true_mean_function(x_test)\n",
    "\n",
    "fig, axes = plt.subplots(theta_values.shape[0], theta_values.shape[1])\n",
    "for n in range(theta_values.shape[0]):\n",
    "    for m in range(theta_values.shape[1]):\n",
    "        thetas = theta_values[n, m]\n",
    "        subplot = axes[n][m]\n",
    "        subplot.set_xlim(0, 1)\n",
    "        mean_test, var_test, C = gp_predictive_distribution(x_train, t_train, x_test, thetas, beta, C)\n",
    "        log_prop, C, invC = gp_log_likelihood(x_train, t_train, thetas, beta, C, invC)\n",
    "        plt.axes(subplot)\n",
    "        gp_plot(x_test, y_test, mean_test, var_test, x_train, t_train, thetas, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54f4c3ac4233129daa34ecc1370cd8f3",
     "grade": false,
     "grade_id": "cell-5d90eb9ba0ec6eed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Support Vector Machines (45 points)\n",
    "As seen in Part 1: Gaussian Processes, one of the significant limitations of many such algorithms is that the kernel function $k(\\bx_n , \\bx_m)$ must be evaluated for all possible pairs $\\bx_n$ and $\\bx_m$ of training points, which can be computationally infeasible during training and can lead to excessive computation times when making predictions for new data points.\n",
    "In Part 2: Support Vector Machines, we shall look at kernel-based algorithms that have sparse solutions, so that predictions for new inputs depend only on the kernel function evaluated at a subset of the training data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e0506a51ec128eeb17ace43d1a5c57d6",
     "grade": false,
     "grade_id": "cell-e89cb4e9ca837b57",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1 Generating a linearly separable dataset (15 points)\n",
    "a) (5 points) First of all, we are going to create our own 2D toy dataset $X$. The dataset will consists of two i.i.d. subsets $X_1$ and $X_2$, each of the subsets will be sampled from a multivariate Gaussian distribution,\n",
    "\n",
    "\\begin{align}\n",
    "X_1 \\sim &\\mathcal{N}(\\mu_1, \\Sigma_1)\\\\\n",
    "&\\text{ and }\\\\\n",
    "X_2 \\sim &\\mathcal{N}(\\mu_2, \\Sigma_2).\n",
    "\\end{align}\n",
    "\n",
    "In the following, $X_1$ will have $N_1=20$ samples and a mean $\\mu_1=(1,1)$. $X_2$ will have $N_2=30$ samples and a mean $\\mu_2=(3,3)$.\n",
    "\n",
    "Plot the two subsets in one figure, choose two colors to indicate which sample belongs to which subset. In addition you should choose, $\\Sigma_1$ and $\\Sigma_2$ in a way that the two subsets become linearly separable. (Hint: Which form has the covariance matrix for a i.i.d. dataset?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cc0901b713f288655ad60a2f1de76e59",
     "grade": true,
     "grade_id": "cell-497b9e4da2d7dd0d",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Set random seed to ensure separability\n",
    "random.seed(1)\n",
    "\n",
    "# Generate X1 and X2 with diagonal covariance matrix\n",
    "X1 = np.random.multivariate_normal((1, 1),  0.6 * np.identity(2) , 20)\n",
    "X2 = np.random.multivariate_normal((3, 3), 0.6 * np.identity(2) , 30)\n",
    "\n",
    "# Plot X1 and X2\n",
    "plt.plot(X1[:,0], X1[:,1],  'bo')\n",
    "plt.plot(X2[:,0], X2[:,1],  'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c9dc67da0bbba1c4fa2a5e292cd56a06",
     "grade": false,
     "grade_id": "cell-e82605073867be20",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "b) (10 points) In the next step we will combine the two datasets X_1, X_2 and generate a vector `t` containing the labels. Write a function `create_X_and_t(X1, X2)` it should return the combined data set X and the corresponding target vector t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7fc0bfcc84c1a33bba7a1201e179192e",
     "grade": false,
     "grade_id": "cell-fb79685c3320a112",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def create_X_and_t(X1, X2):\n",
    "    # Concatenate X1 and X2 into a single data set X\n",
    "    X = np.concatenate((X1, X2)) \n",
    "    \n",
    "    # Create target vector t with -1 for all data in X1 and 1 for all data in X2\n",
    "    t = np.concatenate((np.full((len(X1)), -1), np.full((len(X2)), 1) ))\n",
    "\n",
    "    return X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "27d522f2a6fb516777aee87a6af78149",
     "grade": true,
     "grade_id": "cell-0b007355061e9bf8",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "dim = 2\n",
    "N1_test = 2\n",
    "N2_test = 3\n",
    "X1_test = np.arange(4).reshape((N1_test, dim))\n",
    "X2_test = np.arange(6).reshape((N2_test, dim))\n",
    "X_test, t_test = create_X_and_t(X1_test, X2_test)\n",
    "\n",
    "assert X_test.shape == (N1_test + N2_test, dim), \"the shape of X is incorrect\"\n",
    "assert t_test.shape == (N1_test + N2_test,), \"the shape of t is incorrect\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e43205856d358d616a188c94adaf4ee4",
     "grade": false,
     "grade_id": "cell-9ba2051eb1a59b30",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Finding the support vectors (15 points)\n",
    "Finally we going to use a SVM to obtain the decision boundary for which the margin is maximized. We have to solve the optimization problem\n",
    "\n",
    "\\begin{align}\n",
    "\\arg \\min_{\\bw, b} \\frac{1}{2} \\lVert \\bw \\rVert^2,\n",
    "\\end{align}\n",
    "\n",
    "subject to the constraints\n",
    "\n",
    "\\begin{align}\n",
    "t_n(\\bw^T \\phi(\\bx_n) + b) \\geq 1, n = 1,...,N.\n",
    "\\end{align}\n",
    "\n",
    "In order to solve this constrained optimization problem, we introduce Lagrange multipliers $a_n \\geq 0$. We obtain the dual\n",
    "representation of the maximum margin problem in which we maximize\n",
    "\n",
    "\\begin{align}\n",
    "\\sum_{n=1}^N a_n - \\frac{1}{2}\\sum_{n=1}^N\\sum_{m=1}^N a_n a_m t_n t_m k(\\bx_n, \\bx_m),\n",
    "\\end{align}\n",
    "\n",
    "with respect to a subject to the constraints\n",
    "\n",
    "\\begin{align}\n",
    "a_n &\\geq 0, n=1,...,N,\\\\\n",
    "\\sum_{n=1}^N a_n t_n &= 0.\n",
    "\\end{align}\n",
    "\n",
    "This takes the form of a quadratic programming problem in which we optimize a quadratic function of a subject to a set of inequality constraints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "07d5c4f152011be941d8c3de941643be",
     "grade": false,
     "grade_id": "cell-2737e7ded107f771",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "a) (5 points) In this example we will use a linear kernel $k(\\bx, \\bx') = \\bx^T\\bx'$. Write a function `computeK(X)` that computes the kernel matrix $K$ for the 2D dataset $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6d85e675387e74c4b1f312572e42de4d",
     "grade": false,
     "grade_id": "cell-7d1a17d29190e696",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def computeK(X):\n",
    "    K = empty([len(X),len(X)])\n",
    "    \n",
    "    # Compute kernel matrix with dot product\n",
    "    for n in range(len(X)):\n",
    "        for m in range(len(X)):\n",
    "            K[n][m] = X[n].dot(X[m])    \n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3c02b122890e25420362987db1fad241",
     "grade": true,
     "grade_id": "cell-da1dfa43730cf324",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "N_test = 3\n",
    "X_test = np.arange(6).reshape((N_test, dim))\n",
    "K_test = computeK(X_test)\n",
    "\n",
    "assert K_test.shape == (N_test, N_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will rewrite the dual representation so that we can make use of computationally efficient vector-matrix multiplication. The objective becomes\n",
    "\n",
    "\\begin{align}\n",
    "\\min_{\\ba} \\frac{1}{2} \\ba^T K' \\ba - 1^T\\ba,\n",
    "\\end{align}\n",
    "\n",
    "subject to the constraints\n",
    "\n",
    "\\begin{align}\n",
    "a_n &\\geq 0, n=1,...,N,\\\\\n",
    "\\bt^T\\ba &= 0.\n",
    "\\end{align}\n",
    "\n",
    "Where\n",
    "\\begin{align}\n",
    "K'_{nm} = t_n t_m k(\\bx_n, \\bx_m),\n",
    "\\end{align}\n",
    "and in the special case of a linear kernel function,\n",
    "\\begin{align}\n",
    "K'_{nm} = t_n t_m k(\\bx_n, \\bx_m) = k(t_n \\bx_n, t_m \\bx_m).\n",
    "\\end{align}\n",
    "\n",
    "To solve the quadratic programming problem we will use a python module called cvxopt. You first have to install the module in your virtual environment (you have to activate it first), using the following command:\n",
    "\n",
    "`conda install -c conda-forge cvxopt`\n",
    "\n",
    "The quadratic programming solver can be called as\n",
    "\n",
    "`cvxopt.solvers.qp(P, q[, G, h[, A, b[, solver[, initvals]]]])`\n",
    "\n",
    "This solves the following problem,\n",
    "\n",
    "\\begin{align}\n",
    "\\min_{\\bx} \\frac{1}{2} \\bx^T P \\bx + q^T\\bx,\n",
    "\\end{align}\n",
    "\n",
    "subject to the constraints,\n",
    "\n",
    "\\begin{align}\n",
    "G\\bx &\\leq h,\\\\\n",
    "A\\bx &= b.\n",
    "\\end{align}\n",
    "\n",
    "All we need to do is to map our formulation to the cvxopt interface.\n",
    "\n",
    "b) (10 points) Write a function `compute_multipliers(X, t)` that solves the quadratic programming problem using the cvxopt module and returns the lagrangian multiplier for every sample in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a08a0f87f9dea85bc5fb0eaf47cb5824",
     "grade": false,
     "grade_id": "cell-5b4327394255f3a6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "\n",
    "def compute_multipliers(X, t):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    P = cvxopt.matrix(K)\n",
    "    sol = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    a = np.array(sol['x'])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41db2735e379e37f7225bcb17026fa6b",
     "grade": true,
     "grade_id": "cell-05dd3e69ab4290d5",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "dim = 2\n",
    "N_test = 3\n",
    "X_test = np.arange(6).reshape((N_test, dim))\n",
    "t_test = np.array([-1., 1., 1.])\n",
    "a_test = compute_multipliers(X_test, t_test)\n",
    "\n",
    "assert a_test.shape == (N_test, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f39254febc169743b61bd19896fab2ba",
     "grade": false,
     "grade_id": "cell-79ee552a9c83325e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.3 Plot support vectors (5 points)\n",
    "Now that we have obtained the lagrangian multipliers $\\ba$, we use them to find our support vectors. Repeat the plot from 2.1, this time use a third color to indicate which samples are the support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b9281c423916582fe8b38c6494496099",
     "grade": true,
     "grade_id": "cell-313ecaa7ac15c36c",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d9da1b3e82eee6e95fdfd4b394a8fe7a",
     "grade": false,
     "grade_id": "cell-f2afbd01a7de87e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Plot the decision boundary (10 Points)\n",
    "The decision boundary is fully specified by a (usually very small) subset of training samples, the support vectors. Make use of\n",
    "\n",
    "\\begin{align}\n",
    "\\bw &= \\sum_{n=1}^N a_n t_n \\mathbf{\\phi}(\\bx_n)\\\\\n",
    "b &= \\frac{1}{N_S}\\sum_{n \\in S} (t_n - \\sum_{m \\in S} a_m t_m k(\\bx_n, \\bx_m)),\n",
    "\\end{align}\n",
    "\n",
    "where $S$ denotes the set of indices of the support vectors, to calculate the slope and intercept of the decision boundary. Generate a last plot that contains the two subsets, support vectors and decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d4345049b6609f7e418b186b891d1e9f",
     "grade": true,
     "grade_id": "cell-f9511cd3c125aa65",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
